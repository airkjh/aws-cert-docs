# Amazon Simple Storage Service

## Amazon Simple Storage Service(S3) FAQ

### 일반

#### Amazon S3의 기술적인 혜택은 무엇입니까?

* 확장성
* 신뢰성
* 속도
* 낮은 비용

#### 이전에는 불가능했지만 이제 개발자들이 할 수 있는 작업?

* 정교하고 확장 가능한 데이터 스토리지 인프라 이용
* 개발 작업에 집중

#### 얼마나 많은 데이터를 저장할 수 있나?

* 저장할 수 있는 데이터의 전체 볼륨이나 객체 수에는 제한이 없다
* 객체의 크기는 0바이트에서 5Gb까지 (단일 작업으로 업로드할 경우)
* 5Mb이상의 객체는 멀티 파트 업로드 기능을 이용할 수 있다
  * 멀티 파트 업로드를 이용할 경우 최대 5Tb까지 업로드 가능

#### S3가 제공하는 스토리지의 클래스

* S3 Standard
  * 짧은 지연 시간 및 높은 처리 성능
  * 99.99999999999%의 객체 내구성을 제공하도록 설계
  * 연간 99.99%의 가용성을 제공하도록 설계
  * 전송 데이터와 저장 데이터에 대한 SSL 암호화 지원
  * 객체 자동 마이그레이션을 위한 수명 주기 관리
* S3 Standard - Infrequent Access
  * 엑세스 빈도가 낮지만 필요할 때 빠르게 억세스해야 하는 경우
  * S3 Standard에 비해 저렴한 요금
  * 99.99999999999%의 객체 내구성 제공
  * 99.9%의 가용성 제공
  * 최소 스토리지 기간 : 30일
  * 최소 객체 크기 : 128kb (이보다 작은 크기의 객체에는 128kb의 요금이 부과됨)
  * 검색 요금 : 검색한 GB당
  * 전송 데이터와 저장 데이터에 대한 SSL 암호화 지원
  * 객체 자동 마이그레이션을 위한 수명 주기 관리
* Amazon Glacier
  * 장기간 보관해야 하는 데이터
  * 3가지 억세스 옵션 (수 분 ~ 몇 시간까지 소요)
  * 99.99999999999%의 객체 내구성을 제공하도록 설계
  * 전송 데이터와 저장 데이터에 대한 SSL 암호화 지원
  * 저장소 잠금 기능으로 잠금 가능한 정책을 통해 규정 준수 강화
  * 매우 저렴한 비용으로 장기 아카이브에 최적
  * 객체 자동 마이그레이션을 위한 수명 주기 관리
  * 검색 요금 : 검색한 GB당

### 많은 객체를 삭제하려면

* Multi-Object delete 기능을 이용

#### Amazon은 S3에 저장된 데이터로 무엇을 합니까?

* 법적으로 요구받지 않는 이상 다른 목적으로 사용자의 데이터에 억세스하지 않는다

#### Amazon S3의 데이터는 어떻게 구성됩니까?

* 단순한 키 기반의 객체 스토리지 입니다. 데이터를 저장할 때 데이터를 검색하는데 사용할 수 있는 고유한 객체 키를 할당합니다.
* 키는 임의의 문자열이 될 수 있으며 계측정 속성을 모방하여 만들 수 있습니다 (디렉토리 형태로)

#### S3에서는 어떤 인터페이스를 사용합니까?

* 표준 기반 REST 웹 서비스 인터페이스


#### Amazon S3의 신뢰도는 어느 정도입니까?

* S3 Standard - 99.99%의 SLA
* S3 Standard IA - 99.9%의 SLA

#### Amazon S3는 어떤 데이터 일관성 모델을 사용합니까?

* 새 객체의 PUT에 대한 쓰기 후 읽기 일관성 및 덮어쓰기 PUT 및 DELETE에 대한 최종 일관성을 제공

#### 프로비저닝할 수 있는 Amazon S3 버킷의 수를 늘리려면 어떻게 해야 합니까?

* AWS 계정 당 최대 100개의 버킷을 프로비저닝할 수 있다.
* AWS 지원 센터에 케이스를 열어서 버킷 한도를 늘릴 수 있다

## S3 Details

### 멀티 파트 업로드
* 5Mb이상의 객체는 멀티 파트 업로드 기능을 이용할 수 있다
  * 멀티 파트 업로드를 이용할 경우 최대 5Tb까지 업로드 가능
  * 객체를 파트별로 나누어 업로드할 수 있다
    * 임의의 순서로, 독립적으로, 병렬적으로 업로드 (멀티스레드 이용)
    * 네트워크가 불안정한 경우 멀티 파트 업로드가 실패하면 실패한 파트만 다시 업로드할 수 있다
  * 기존 객체의 복사본을 만드는데도 사용할 수 있다

#### 멀티 파트 업로드의 단계

* 멀티 파트 업로드의 시작
  * 멀티 파트 업로드 시작 요청을 전송하면 S3가 멀티 파트 업로드에 대한 고유 식별자인 업로드 ID화 함께 응답을 반환
  * 파트 업로드, 부분 목록 확인, 업로드 확인, 업로드 중단 요청시 반드시 업로드 ID를 포함해야 한다
* 파트 업로드
  * 부분을 업로드할 때는 업로드 ID와 부분 번호를 지정해야 한다
  * 1~10000까지 부분 번호 지정 가능
  * 부분 번호가 연속된 시퀀스이지 않아도 된다
  * 이전에 업로드한 부분과 동일한 부분 번호로 업로드하면 기존에 업로드했던 부분을 덮어쓰게 된다
  * 부분을 업로드할 때마다 S3는 ETag 헤더를 반환한다
  * 각 파트 업로드에 대해 부분 번호와 ETag를 기록해야 한다
    * 이후 업로드를 완료하기 위한 요청에 필요함
  * 업로드 진행 후 완료 혹은 중단 요청을 보내야 임시로 저장한 파트에 대한 스토리지 요금이 청구되지 않는다
* 멀티 파트 업로드의 완료 (혹은 중단)
  * 파트 업로드가 완료되면 S3는 부분 번호를 기준으로 오름차순으로 각 부분을 결합하여 업로드를 완료함
  * 멀티 파트 업로드 요청시 객체 메타 데이터가 포함되었다면 결합된 객체에 메타 데이터를 적용
  * 업로드 완료 요청에는 업로드 ID와 각 파트의 부분 번호 및 해당 ETag 헤더가 포함되어야 함
  * 멀티 파트 업로드를 중단한 경우 동일한 업로드 ID로 업로드할 수 없음
  * 중단된 업로드의 파트 데이터는 삭제된다
  * 업로드를 중단해도 업로드 과정이 진행 중이었던 파트의 업로드는 계속 진행될 수 있따. (따라서 파트 업로드가 완료된 후에 멀티 파트 업로들를 중단해야 한다)

#### 멀티 파트 업로드의 나열

* 특정 멀티 파트 업로드 혹은 진행 중인 모든 멀티 파트 업로드에 대한 부분 목록을 조회할 수 있다
* 파트 목록 조회 작업은 특정 멀티 파트 업로드에 대해 업로드한 부분에 대한 정보를 반환 (업로드가 완료되지 않으면 목록에 포함되지 않음)
* 진행 중인 모든 멀티 파티 업로드 조회는 업로드를 시작하였지만 아직 완료 또는 중단되지 않은 업로드
* 두 조회 작업 모두 한 번에 반환하는 목록은 최대 1000개 (1000개 이상인 경우 반복해서 조회)

#### 멀티 파트 업로드 요금

* 멀티 파트 업로드가 시작되면 S3는 업로드가 중단되거나 완료될 때까지 모든 파트 정보를 보존한다
* 수명 주기가 끝날 때까지 멀티파트와 관련된 모든 스토리지, 대역폭 및 요청에 대해 비용이 청구됨
* 업로드가 완료된 후 중단 요청을 보내면 업로드된 파트 정보를 삭제한다
* 업로드가 완료된 후 완료 요청을 보내면 파트를 순서대로 조합한 후 객체를 생성하고 파트 정보를 삭제한다

#### 버킷 수명 주기 정책을 사용한 미완료 멀티 파트 업로드 중단

* 수명 주기 규칙 (AbortIncompleteMultipartUpload 작업 사용)을 구성할 것을 권장
* 시작된 후 지정 일수 내에 완료되지 않은 멀티 파트 업로드를 중단하도록 버킷 수명 규칙을 지원
* 예시

```
<LifeCycleConfiguration>
  <Rule>
    <ID>sample-rule</ID>
    <Prefix></Prefix>
    <Status>Enabled</Status>
    <AbortIncompleteMultipartUpload>
      <DaysAfterInitiation>7</DaysAfterInitiation>
    </AbortIncompleteMultipartUpload>
  </Rule>
</LifeCycleConfiguration>
```

```
# Lifecycle 설정
$ aws s3api put-bucket-lifecycle \
    --bucket <bucketname>
    --lifecycle-configuration file://<filename>

# Lifecycle 확인
$ aws s3api get-bucket-lifecycle --bucket <bucketname>

# Lifecycle 삭제
$ aws s3api delete-bucket-lifecycle --bucket <bucketname>
```
